{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73fb57e7",
   "metadata": {
    "papermill": {
     "duration": 0.003631,
     "end_time": "2025-07-20T13:57:50.729214",
     "exception": false,
     "start_time": "2025-07-20T13:57:50.725583",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Market States approach\n",
    "\n",
    "- From the observations that with tabular models (gradient boosting ensemble),\n",
    "shuffling the data guarantees no overfitting \n",
    "while splitting with chronological order overfits / does not capture the test probability distribution, \n",
    "it seems like a time-series approach is necessary :\n",
    "timestamps are not independant draws of one underlying random variable.\n",
    "- Defining some latent state of the time-series is expected to be an improvement,\n",
    "- Also possible to cluster the timesteps into market modes, then to fit a predictor for each market mode.\n",
    "- Market modes can be defined from the covariance matrix of the features\n",
    "- Covariance matrix filtering techniques to reduce noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7beff",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-20T13:57:50.736615Z",
     "iopub.status.busy": "2025-07-20T13:57:50.736306Z",
     "iopub.status.idle": "2025-07-20T13:58:00.995242Z",
     "shell.execute_reply": "2025-07-20T13:58:00.994253Z"
    },
    "papermill": {
     "duration": 10.264046,
     "end_time": "2025-07-20T13:58:00.996596",
     "exception": false,
     "start_time": "2025-07-20T13:57:50.732550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"/kaggle/\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "KAGGLE = False  # define paths accordingly\n",
    "SUBMISSION = False  # use smaller datasets during dev\n",
    "\n",
    "if KAGGLE:\n",
    "    crypto_folder = Path(\"/kaggle/input/drw-crypto-market-prediction\")\n",
    "else:\n",
    "    crypto_folder = Path(\"../raw_data/crypto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e19db",
   "metadata": {
    "papermill": {
     "duration": 0.002666,
     "end_time": "2025-07-20T13:58:01.002348",
     "exception": false,
     "start_time": "2025-07-20T13:58:00.999682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d61f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T13:58:01.010035Z",
     "iopub.status.busy": "2025-07-20T13:58:01.009379Z",
     "iopub.status.idle": "2025-07-20T13:58:01.021835Z",
     "shell.execute_reply": "2025-07-20T13:58:01.021043Z"
    },
    "papermill": {
     "duration": 0.018102,
     "end_time": "2025-07-20T13:58:01.023357",
     "exception": false,
     "start_time": "2025-07-20T13:58:01.005255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_clean_crypto_data(train: bool = True) -> pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    Load and clean crypto data, returning either train or test set.\n",
    "\n",
    "    Args:\n",
    "        train: If True, return training set. If False, return test set.\n",
    "\n",
    "    Returns:\n",
    "        Cleaned lazy frame with columns that have variance and no infinite values.\n",
    "    \"\"\"\n",
    "\n",
    "    filename = \"train.parquet\" if train else \"test.parquet\"\n",
    "\n",
    "    # load data\n",
    "    crypto_lazy = pl.scan_parquet(crypto_folder / filename)\n",
    "    n_cols = len(crypto_lazy.collect_schema().names())\n",
    "\n",
    "    if train and KAGGLE:\n",
    "        # rename timestamp column\n",
    "        crypto_lazy = crypto_lazy.with_columns(\n",
    "            pl.col(\"__index_level_0__\").alias(\"timestamp\")\n",
    "        ).drop([\"__index_level_0__\"])\n",
    "\n",
    "    # Remove columns with zero variance in the training set\n",
    "    train_lazy = pl.scan_parquet(crypto_folder / \"train.parquet\")\n",
    "    if KAGGLE:\n",
    "        train_lazy = train_lazy.with_columns(\n",
    "            pl.col(\"__index_level_0__\").alias(\"timestamp\")\n",
    "        ).drop([\"__index_level_0__\"])\n",
    "\n",
    "    # Get column names and calculate variance on training set (for consistency)\n",
    "    crypto_var = train_lazy.select(pl.exclude([\"timestamp\"]).var())\n",
    "\n",
    "    crypto_var_cols = (\n",
    "        crypto_var.select(pl.all() == 0.0)\n",
    "        .first()\n",
    "        .collect()\n",
    "        .to_pandas()\n",
    "        .T.rename(columns={0: \"is_variance_null\"})\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"column_name\"})\n",
    "        .groupby(\"is_variance_null\")[\"column_name\"]\n",
    "        .unique()\n",
    "    )\n",
    "\n",
    "    crypto_cols_with_var = crypto_var_cols[False]\n",
    "\n",
    "    try:\n",
    "        cols_no_var = crypto_var_cols[True]\n",
    "        print(f\"Columns with no variance : {cols_no_var}\")\n",
    "    except KeyError:\n",
    "        print(\"All columns have variance in the train set\")\n",
    "\n",
    "    # remove columns that have no variance in the training set\n",
    "    train_lazy = train_lazy.select(\n",
    "        [\"timestamp\"] + [pl.col(c) for c in crypto_cols_with_var]\n",
    "    )\n",
    "\n",
    "    # Remove columns with infinite values (check on training set)\n",
    "    current_columns = train_lazy.collect_schema().names()\n",
    "    contains_infinite_cols = (\n",
    "        train_lazy.select(pl.exclude(\"timestamp\").abs().max().is_infinite())\n",
    "        .collect()\n",
    "        .to_pandas()\n",
    "        .T.rename(columns={0: \"contains_infinite\"})\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"column_name\"})\n",
    "        .groupby(\"contains_infinite\")[\"column_name\"]\n",
    "        .unique()\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        cols_with_inf_vals = contains_infinite_cols[True]\n",
    "        print(f\"Columns with infinite values : {cols_with_inf_vals}\")\n",
    "    except KeyError:\n",
    "        print(\"No columns with infinite values\")\n",
    "\n",
    "    if not train:\n",
    "        # add dummy timestamps\n",
    "        crypto_lazy = crypto_lazy.with_columns(\n",
    "            ID=range(1, crypto_lazy.select(pl.len()).collect().item() + 1)\n",
    "        )\n",
    "    # Filter clean columns based on what's available in the current dataset\n",
    "    clean_columns = [\n",
    "        c for c in current_columns if c in contains_infinite_cols[False]\n",
    "    ] + [\"timestamp\", \"ID\"]\n",
    "    available_columns = crypto_lazy.collect_schema().names()\n",
    "    final_columns = [c for c in clean_columns if c in available_columns]\n",
    "    print(f\"Eventually {len(final_columns)}, removed {n_cols - len(final_columns)}\")\n",
    "\n",
    "    return crypto_lazy.select(final_columns)\n",
    "\n",
    "\n",
    "def get_diff_features(df: pl.LazyFrame, stats_columns: List[str]):\n",
    "    return (\n",
    "        df.with_columns(pl.exclude(stats_columns).diff())\n",
    "        .with_row_index()\n",
    "        .fill_null(strategy=\"backward\")\n",
    "        .select(pl.exclude(\"index\"))\n",
    "    )\n",
    "\n",
    "\n",
    "def get_ma_features(df: pl.LazyFrame, cols: List[str]):\n",
    "    return df.with_columns(pl.col(cols).rolling_mean(window_size=23, min_samples=1))\n",
    "\n",
    "\n",
    "def get_rolling_var(df: pl.LazyFrame, cols: List[str]):\n",
    "    return df.with_columns(pl.col(cols).rolling_var(window_size=23, min_samples=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35d2906",
   "metadata": {
    "papermill": {
     "duration": 0.002735,
     "end_time": "2025-07-20T13:58:01.029189",
     "exception": false,
     "start_time": "2025-07-20T13:58:01.026454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b32e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T13:58:01.036667Z",
     "iopub.status.busy": "2025-07-20T13:58:01.036030Z",
     "iopub.status.idle": "2025-07-20T13:58:01.040747Z",
     "shell.execute_reply": "2025-07-20T13:58:01.039986Z"
    },
    "papermill": {
     "duration": 0.010025,
     "end_time": "2025-07-20T13:58:01.042131",
     "exception": false,
     "start_time": "2025-07-20T13:58:01.032106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stats_columns = [\n",
    "    \"timestamp\",\n",
    "    \"bid_qty\",\n",
    "    \"ask_qty\",\n",
    "    \"buy_qty\",\n",
    "    \"sell_qty\",\n",
    "    \"volume\",\n",
    "    \"label\",\n",
    "]\n",
    "stats_columns_test = [\n",
    "    \"ID\",\n",
    "    \"bid_qty\",\n",
    "    \"ask_qty\",\n",
    "    \"buy_qty\",\n",
    "    \"sell_qty\",\n",
    "    \"volume\",\n",
    "    \"label\",\n",
    "]\n",
    "X_exclude = [\"timestamp\", \"label\"]\n",
    "X_test_exclude = [\"ID\", \"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cafcef9",
   "metadata": {
    "papermill": {
     "duration": 0.002802,
     "end_time": "2025-07-20T13:58:01.048043",
     "exception": false,
     "start_time": "2025-07-20T13:58:01.045241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd0fff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T13:58:01.054968Z",
     "iopub.status.busy": "2025-07-20T13:58:01.054690Z",
     "iopub.status.idle": "2025-07-20T13:58:29.777066Z",
     "shell.execute_reply": "2025-07-20T13:58:29.775983Z"
    },
    "papermill": {
     "duration": 28.727997,
     "end_time": "2025-07-20T13:58:29.778904",
     "exception": false,
     "start_time": "2025-07-20T13:58:01.050907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create intermediate clean file\n",
    "crypto_lazy_clean = get_clean_crypto_data(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47c68b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dataset to day columns and only X features\n",
    "\n",
    "crypto_df = crypto_lazy_clean.select(pl.exclude(stats_columns)).collect().to_pandas().T\n",
    "crypto_df.to_parquet(\"features.parquet\")\n",
    "del crypto_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f7b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lazy.collect_schema().names()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce1f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lazy.collect_schema().names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be651c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lazy = pl.scan_parquet(\"features.parquet\").drop(\"__index_level_0__\")\n",
    "cols = features_lazy.collect_schema().names()\n",
    "features_lazy = features_lazy.select(pl.col(cols[:200]))\n",
    "n = len(features_lazy.collect_schema().names())\n",
    "lazy_cor = pl.concat(\n",
    "    [\n",
    "        features_lazy.select(pl.corr(pl.all(), pl.col(f\"{i}\"))).collect()\n",
    "        for i in range(n)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882562bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(lazy_cor.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196fbe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = 1.0 - lazy_cor.to_numpy()\n",
    "\n",
    "adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9bcbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"adjancency_matrix.npy\", adjacency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd3c6ee",
   "metadata": {},
   "source": [
    "## Filter covariance matrix between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc79d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50_000\n",
    "cov = crypto[[c for c in cols if c not in stats_columns]].sample(n_samples).cov()\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed9f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = crypto[[c for c in cols if c not in stats_columns]].sample(n_samples).corr()\n",
    "plt.imshow(cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044ce3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = np.linalg.svd(cov.values, hermitian=True)\n",
    "U, S = svd.U, svd.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611e588",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.bar(range(len(S)), S)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.axhline(0.1, c=\"red\", linestyle=\"--\")\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a671bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_clean = U @ np.diag(np.where(S > 1.0, S, np.zeros_like(S))) @ U.T\n",
    "\n",
    "plt.imshow(cov_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655a1d5c",
   "metadata": {},
   "source": [
    "## Compute day-wise covariance matrix to cluster timestamps into market modes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770d183e",
   "metadata": {},
   "source": [
    "### Compute Louvain network communities and plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a95e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from sknetwork.data import karate_club, painters, movie_actor\n",
    "from sknetwork.clustering import Louvain, get_modularity\n",
    "from sknetwork.linalg import normalize\n",
    "from sknetwork.utils import get_membership\n",
    "from sknetwork.visualization import visualize_graph, visualize_bigraph\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "adjacency_np = np.load(\"adjancency_matrix.npy\")\n",
    "adjacency = csr_matrix(adjacency_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f191ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain = Louvain()\n",
    "labels = louvain.fit_predict(adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c2d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_unique, counts = np.unique(labels, return_counts=True)\n",
    "print(labels_unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4616aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(labels_unique)\n",
    "cx = np.random.randn(2 * k) * 10\n",
    "cx = cx.reshape((k, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea38fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# position = np.random.randn(400).reshape((200, 2))\n",
    "position = np.array([cx[l] for l in labels]) + np.random.randn(400).reshape((200, 2))\n",
    "image = visualize_graph(adjacency, position, labels=labels, display_edges=False)\n",
    "SVG(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69afef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_score(features_lazy.collect().to_numpy().T, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ec406",
   "metadata": {},
   "source": [
    "### Compute estimated transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd01b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = np.zeros((k, k), dtype=np.float64)\n",
    "for l_prev, l in zip(labels[:-1], labels[1:]):\n",
    "    transitions[l_prev, l] += 1.0\n",
    "transitions = transitions / np.sum(transitions, axis=1)[:, None]\n",
    "plt.imshow(transitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99a0648",
   "metadata": {},
   "source": [
    "- train a classifier to distinguish market modes\n",
    "    - PCA to define relevant samples for each modes, then KNN to classify new samples\n",
    "    - need train data classification guarantees, otherwise market mode feature will be very lossy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb27053c",
   "metadata": {},
   "source": [
    "## Compute adjacency matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cb6f3c",
   "metadata": {},
   "source": [
    "## Apply Louvain clustering algorithm of community detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b8de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = crypto_lazy_clean.select(pl.exclude(X_exclude)).collect().to_numpy()\n",
    "y = crypto_lazy_clean.select(pl.col(\"label\")).collect().to_numpy().T[0]\n",
    "\n",
    "if not SUBMISSION:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        shuffle=False,  # TODO : question this, whether timestamps are independant draws\n",
    "        random_state=42,\n",
    "    )\n",
    "else:\n",
    "    X_train, y_train = X, y\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774266cd",
   "metadata": {
    "papermill": {
     "duration": 0.003242,
     "end_time": "2025-07-20T13:58:29.786476",
     "exception": false,
     "start_time": "2025-07-20T13:58:29.783234",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0a28bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T13:58:29.794669Z",
     "iopub.status.busy": "2025-07-20T13:58:29.794329Z",
     "iopub.status.idle": "2025-07-20T14:09:33.326111Z",
     "shell.execute_reply": "2025-07-20T14:09:33.324890Z"
    },
    "papermill": {
     "duration": 663.54052,
     "end_time": "2025-07-20T14:09:33.330618",
     "exception": false,
     "start_time": "2025-07-20T13:58:29.790098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 1.0\n",
    "\n",
    "lin = RandomForestRegressor(\n",
    "    # fit_intercept=True,\n",
    "    n_estimators=80,\n",
    "    n_jobs=-1,\n",
    "    max_depth=10,\n",
    "    min_samples_split=100,\n",
    "    min_samples_leaf=50,\n",
    "    max_features=\"sqrt\",\n",
    "    max_samples=0.5,\n",
    "    random_state=41,\n",
    ")\n",
    "# n_samples = 80_000\n",
    "lin.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    # sample_weight=np.flip(1.0 / np.sqrt(np.arange(1, n_samples+1)))\n",
    ")\n",
    "\n",
    "y_train_lin = lin.predict(X_train)\n",
    "\n",
    "print(f\"R2 train lin: {r2_score(y_train, y_train_lin)}\")\n",
    "print(f\"Pearson train lin : {pearsonr(y_train, y_train_lin)}\")\n",
    "\n",
    "y_train_res = y_train - lr * y_train_lin\n",
    "\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    random_state=42,\n",
    "    # weight=np.flip(1.0 / np.sqrt(np.arange(1, len(X_train)+1))),\n",
    "    # n_estimators=80,\n",
    "    # max_depth=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "lgb_model.fit(X_train, y_train_res)\n",
    "\n",
    "y_train_hat = lgb_model.predict(X_train)\n",
    "\n",
    "print(f\"R2 train : {r2_score(y_train, y_train_hat + lr * y_train_lin)}\")\n",
    "print(f\"Pearson train : {pearsonr(y_train, y_train_hat + lr * y_train_lin)}\")\n",
    "\n",
    "if not SUBMISSION:\n",
    "    y_test_lin = lin.predict(X_test)\n",
    "\n",
    "    print(f\"R2 test lin : {r2_score(y_test, y_test_lin)}\")\n",
    "    print(f\"Pearson test lin : {pearsonr(y_test, y_test_lin)}\")\n",
    "\n",
    "    y_test_hat = lgb_model.predict(X_test)\n",
    "\n",
    "    print(f\"R2 test : {r2_score(y_test, y_test_hat + lr * y_test_lin)}\")\n",
    "    print(f\"Pearson test : {pearsonr(y_test, y_test_hat + lr * y_test_lin)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d60892b",
   "metadata": {
    "papermill": {
     "duration": 0.003269,
     "end_time": "2025-07-20T14:09:33.337700",
     "exception": false,
     "start_time": "2025-07-20T14:09:33.334431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4c999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T14:09:33.346111Z",
     "iopub.status.busy": "2025-07-20T14:09:33.345767Z",
     "iopub.status.idle": "2025-07-20T14:09:49.226476Z",
     "shell.execute_reply": "2025-07-20T14:09:49.225520Z"
    },
    "papermill": {
     "duration": 15.886968,
     "end_time": "2025-07-20T14:09:49.228000",
     "exception": false,
     "start_time": "2025-07-20T14:09:33.341032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "crypto_lazy_test = get_clean_crypto_data(train=False)\n",
    "\n",
    "# create unique row identifier\n",
    "n = crypto_lazy_test.select(pl.len()).collect().item()\n",
    "crypto_lazy_test = crypto_lazy_test.with_columns(ID=range(1, n + 1))\n",
    "\n",
    "print(crypto_lazy_test.select(pl.len()).collect().item())\n",
    "\n",
    "crypto_lazy_test = crypto_lazy_test.join(\n",
    "    get_diff_features(crypto_lazy_test, stats_columns_test),\n",
    "    on=stats_columns_test,\n",
    "    how=\"inner\",\n",
    "    suffix=\"_diff\",\n",
    ")\n",
    "\n",
    "# crypto_lazy_test = get_diff_features(crypto_lazy_test, stats_columns_test)\n",
    "assert n == crypto_lazy_test.select(pl.len()).collect().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6556135c",
   "metadata": {
    "papermill": {
     "duration": 0.003187,
     "end_time": "2025-07-20T14:09:49.235751",
     "exception": false,
     "start_time": "2025-07-20T14:09:49.232564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predict target \\& submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a848f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T14:09:49.243816Z",
     "iopub.status.busy": "2025-07-20T14:09:49.243525Z",
     "iopub.status.idle": "2025-07-20T14:10:31.110731Z",
     "shell.execute_reply": "2025-07-20T14:10:31.107856Z"
    },
    "papermill": {
     "duration": 41.873573,
     "end_time": "2025-07-20T14:10:31.112620",
     "exception": false,
     "start_time": "2025-07-20T14:09:49.239047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = crypto_lazy_test.select(pl.exclude(X_test_exclude)).collect().to_numpy()\n",
    "y_lin_test = lin.predict(X_test)\n",
    "y_hat_lgb_test = lgb_model.predict(X_test)\n",
    "\n",
    "del X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56074ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T14:10:31.125471Z",
     "iopub.status.busy": "2025-07-20T14:10:31.125146Z",
     "iopub.status.idle": "2025-07-20T14:10:38.514189Z",
     "shell.execute_reply": "2025-07-20T14:10:38.509917Z"
    },
    "papermill": {
     "duration": 7.39843,
     "end_time": "2025-07-20T14:10:38.517545",
     "exception": false,
     "start_time": "2025-07-20T14:10:31.119115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "crypto_lazy_test = crypto_lazy_test.with_columns(\n",
    "    ID=range(1, n + 1), prediction=y_hat_lgb_test + lr * y_lin_test\n",
    ")\n",
    "crypto_lazy_test.head(5).collect()\n",
    "crypto_lazy_test.select([pl.col(\"ID\"), pl.col(\"prediction\")]).collect().write_csv(\n",
    "    Path(\"submission.csv\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12993472,
     "sourceId": 96164,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "irbackend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 777.076344,
   "end_time": "2025-07-20T14:10:42.981129",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-20T13:57:45.904785",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
